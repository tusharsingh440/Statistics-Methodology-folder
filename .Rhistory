method          = meth,
predictorMatrix = predMat,
seed            = 235711)
## Remove the factor variables from each imputed dataset (because we don't want
## categorical variables in our data when checking for multivariate outliers):
miceOut2 <-
subset_datlist(datlist = miceOut,
select  = setdiff(colnames(bfi), c("gender", "education")),
toclass = "mids")
## Create list of multiply imputed datasets:
impList <- complete(miceOut2, "all")
## Check for multivariate outliers in each imputed datset:
olList <- lapply(impList, mdOutliers, critProb = 0.99)
## Define the threshold for voting (will be 10 in this case):
thresh <- ceiling(miceOut$m / 2)
## Define a vector of row indices for outliers:
outs <- as.numeric(names(olCounts[olCounts >= thresh]))
## Count the number of times each observation is flagged as an outlier:
olCounts <- table(unlist(olList))
## Define the threshold for voting (will be 10 in this case):
thresh <- ceiling(miceOut$m / 2)
## Define a vector of row indices for outliers:
outs <- as.numeric(names(olCounts[olCounts >= thresh]))
## Exclude outlying observations from mids object:
miceOut3 <- subset_datlist(datlist = miceOut, # We're using the original imputations
subset  = setdiff(1 : nrow(bfi), outs),
toclass = "mids")
set.seed(221291)
index <- sample(
c(rep("train", 7500), rep("valid", 2000), rep("test", n - 9500))
)
MIlist2 <- splitImps(imps = miceOut3, index = index)
source("miPredictionRoutines.R")
MIlist2 <- splitImps(imps = miceOut3, index = index)
str(miceOut3)
View(miceOut3)
View(dat0)
View(wvs_data_NA)
setwd("C:/Users/Tushar/AppData/Local/Temp/Temp1_group36 (1).zip/group36 project/code")
# Cleanup to start
rm(list = ls(all = TRUE))
# Load packages needed for data cleaning:
library(mice) # For missing data descriptives & MI
library(MASS) # For robust stats
library(naniar) # For NA values
library(dplyr) # For filtering the dataset
library(mitools) # For MI
library(MLmetrics) # We'll need this for MSEs
## Source the "studentFunctions.R" script to get the cv.lm function:
source("studentFunctions.R")
## Source the "miPredictionRoutines.R" script to get MI-based prediction stuff:
source("miPredictionRoutines.R")
# Cleanup to start
rm(list = ls(all = TRUE))
setwd("C:/Users/Tushar/Downloads/group36 project/code")
# Load packages needed for data cleaning:
library(mice) # For missing data descriptives & MI
library(MASS) # For robust stats
library(naniar) # For NA values
library(dplyr) # For filtering the dataset
library(mitools) # For MI
library(MLmetrics) # We'll need this for MSEs
## Source the "studentFunctions.R" script to get the cv.lm function:
source("studentFunctions.R")
## Source the "miPredictionRoutines.R" script to get MI-based prediction stuff:
source("miPredictionRoutines.R")
set.seed(221291) # Set the random number seed
# Define the data directory:
dataDir <- "../code/"
## Load the data file ##
wvs_data <- readRDS(paste0("wvs_data.rds"))
## Multivariate outlier list (to save time when running the code) ##
m_out <- readRDS(paste0("mult_outlier.rds"))
# Get the variables that are relevant for our analysis
wvs_data_filter <- wvs_data %>% select(V2, V8, V45, V47:V48, V52, V53:V54, V96,
V139, V240, V242,
V71, V81, V97, V99, V101,
V181:V182, V229, V237:V239,
V23, V57:V58, V191, V59)
# Changing names of the variables so they are more informative (Gender Politics)
wvs_data_filter <- wvs_data_filter %>% rename(country_code = V2, availableJob_inequality = V45, Wwage_inequality = V47, Wjob_independence = V48,
education_inequality = V52, business_inequality = V53, Whouse_fulfillment = V54,
equal_rights = V139, Sex = V240, Age = V242)
# Changing names of the variables so they are more informative (Financial Satisfaction)
wvs_data_filter <- wvs_data_filter %>% rename(education_availability = V182, life_satisfaction = V23, Marital_status = V57,
nr_children = V58, no_cash = V191, financial_satisfaction = V59)
negative_values <- c(-1:-5)
wvs_data_filter <- replace_with_na_all(wvs_data_filter, ~.x %in% negative_values)
wvs_data_filter
summary(wvs_data_filter)
# Count the missing values in each feature
cm <- colSums(is.na(wvs_data_filter))
cm
pm <- colMeans(is.na(wvs_data_filter))
pm
# Count the observed values in each feature
co <- colSums(!is.na(wvs_data_filter))
co
po <- colMeans(!is.na(wvs_data_filter))
po
# Alternative of observed values
nrow(wvs_data_filter) - cm
1 - pm
# Alternative of missing values
nrow(wvs_data_filter) - co
1 - po
# Some stats on the missing percentages
range(pm)
mean(pm)
median(pm)
# All features that miss at least 10% of their data
pm[pm > 0.1]
# Missing patterns in the data
missPat <- md.pattern(wvs_data_filter)
missPat
dev.off()
missPat[ , ncol(missPat)]
missPat[-nrow(missPat), ncol(missPat)]
as.numeric(rownames(missPat))
as.numeric(rownames(missPat))[-nrow(missPat)]
# Covariance coverage
cc <- md.pairs(wvs_data_filter)$rr / nrow(wvs_data_filter)
cc
range(cc)
eps <- 0.8
all(cc > eps)
pat <- cc <= eps
apply(pat, 1, function(x) names(x)[x])
cc[lower.tri(cc, diag = TRUE)]
# Univariate outliers using the boxplot method
boxplot.stats(wvs_data_filter$private_state_ownership)
x <- wvs_data_filter$private_state_ownership
# Define a function to implement the boxplot method:
bpOutliers <- function(x) {
iFen <- boxplot.stats(x, coef = 1.5)$stats[c(1, 28)]
oFen <- boxplot.stats(x, coef = 3.0)$stats[c(1, 28)]
list(possible = which(x < iFen[1] | x > iFen[2]),
probable = which(x < oFen[1] | x > oFen[2])
)
}
lapply(wvs_data_filter[ , -c(1, 11)], FUN = bpOutliers)
# Some EDA for plotting the outliers
hist(wvs_data_filter$education_inequality)
hist(wvs_data_filter$equal_rights)
hist(wvs_data_filter$social_class)
# Using Winsorization to treat the Univariate outliers
# For education inequality (3 is for the 1st quantile value)
summary(wvs_data_filter$education_inequality)
lower_threshold1 <- round(3.0 - IQR(wvs_data_filter$education_inequality, na.rm = TRUE) * 1.5)
lower_threshold1
wvs_data_filter$education_inequality <- replace(wvs_data_filter$education_inequality, wvs_data_filter$education_inequality < 2, lower_threshold1)
hist(wvs_data_filter$education_inequality)
# For equal rights (8 is for the 1st quantile value)
summary(wvs_data_filter$equal_rights)
lower_threshold2 <- round(8 - IQR(wvs_data_filter$equal_rights, na.rm = TRUE) * 1.5)
lower_threshold2
wvs_data_filter$equal_rights <- replace(wvs_data_filter$equal_rights, wvs_data_filter$equal_rights < 5, lower_threshold2)
hist(wvs_data_filter$equal_rights)
# For equal rights (3 is for the 1st quantile value)
summary(wvs_data_filter$social_class)
lower_threshold3 <- round(3.0 - IQR(wvs_data_filter$social_class, na.rm = TRUE) * 1.5)
lower_threshold3
wvs_data_filter$social_class <- replace(wvs_data_filter$social_class, wvs_data_filter$social_class < 2, lower_threshold3)
hist(wvs_data_filter$social_class)
predM <- quickpred(wvs_data_filter, mincor = 0.2, include = "Sex")
miceOut1 <- mice(wvs_data_filter, m = 10, maxit = 5, predictorMatrix = predM, seed = 221291)
# Cleanup to start
rm(list = ls(all = TRUE))
setwd("C:/Users/Tushar/Downloads/group36 project/code")
# Load packages needed for data cleaning:
library(mice) # For missing data descriptives & MI
library(MASS) # For robust stats
library(naniar) # For NA values
library(dplyr) # For filtering the dataset
library(mitools) # For MI
library(MLmetrics) # We'll need this for MSEs
## Source the "studentFunctions.R" script to get the cv.lm function:
source("studentFunctions.R")
## Source the "miPredictionRoutines.R" script to get MI-based prediction stuff:
source("miPredictionRoutines.R")
set.seed(221291) # Set the random number seed
# Define the data directory:
dataDir <- "../code/"
## Load the data file ##
wvs_data <- readRDS(paste0("wvs_data.rds"))
# Define the data directory:
dataDir <- "../code/"
## Multivariate outlier list (to save time when running the code) ##
m_out <- readRDS(paste0("mult_outlier.rds"))
# Get the variables that are relevant for our analysis
wvs_data_filter <- wvs_data %>% select(V2, V8, V45, V47:V48, V52, V53:V54, V96,
V139, V240, V242,
V71, V81, V97, V99, V101,
V181:V182, V229, V237:V239,
V23, V57:V58, V191, V59)
# Changing names of the variables so they are more informative (Gender Politics)
wvs_data_filter <- wvs_data_filter %>% rename(country_code = V2, availableJob_inequality = V45, Wwage_inequality = V47, Wjob_independence = V48,
education_inequality = V52, business_inequality = V53, Whouse_fulfillment = V54,
equal_rights = V139, Sex = V240, Age = V242)
# Changing names of the variables so they are more informative (Economic Beliefs)
wvs_data_filter <- wvs_data_filter %>% rename(work_importance = V8, importance_wealth = V71, economy_environment = V81, income_equality = V96,
private_state_ownership = V97, view_on_competition = V99, wealth_accumulation = V101,
job_security = V181, employment_status = V229, family_saving = V237,
social_class = V238, scale_income = V239)
# Changing names of the variables so they are more informative (Financial Satisfaction)
wvs_data_filter <- wvs_data_filter %>% rename(education_availability = V182, life_satisfaction = V23, Marital_status = V57,
nr_children = V58, no_cash = V191, financial_satisfaction = V59)
negative_values <- c(-1:-5)
wvs_data_filter <- replace_with_na_all(wvs_data_filter, ~.x %in% negative_values)
wvs_data_filter
summary(wvs_data_filter)
# Count the missing values in each feature
cm <- colSums(is.na(wvs_data_filter))
cm
pm <- colMeans(is.na(wvs_data_filter))
pm
# Count the observed values in each feature
co <- colSums(!is.na(wvs_data_filter))
co
po <- colMeans(!is.na(wvs_data_filter))
po
# Alternative of observed values
nrow(wvs_data_filter) - cm
1 - pm
# Alternative of missing values
nrow(wvs_data_filter) - co
1 - po
# Some stats on the missing percentages
range(pm)
mean(pm)
median(pm)
# All features that miss at least 10% of their data
pm[pm > 0.1]
# Missing patterns in the data
missPat <- md.pattern(wvs_data_filter)
missPat
dev.off()
missPat[ , ncol(missPat)]
missPat[-nrow(missPat), ncol(missPat)]
as.numeric(rownames(missPat))
as.numeric(rownames(missPat))[-nrow(missPat)]
# Covariance coverage
cc <- md.pairs(wvs_data_filter)$rr / nrow(wvs_data_filter)
cc
range(cc)
eps <- 0.8
all(cc > eps)
pat <- cc <= eps
apply(pat, 1, function(x) names(x)[x])
cc[lower.tri(cc, diag = TRUE)]
# Univariate outliers using the boxplot method
boxplot.stats(wvs_data_filter$private_state_ownership)
x <- wvs_data_filter$private_state_ownership
# Define a function to implement the boxplot method:
bpOutliers <- function(x) {
iFen <- boxplot.stats(x, coef = 1.5)$stats[c(1, 28)]
oFen <- boxplot.stats(x, coef = 3.0)$stats[c(1, 28)]
list(possible = which(x < iFen[1] | x > iFen[2]),
probable = which(x < oFen[1] | x > oFen[2])
)
}
rm(list = c("x"))
lapply(wvs_data_filter[ , -c(1, 11)], FUN = bpOutliers)
as.numeric(rownames(missPat))
as.numeric(rownames(missPat))[-nrow(missPat)]
# Covariance coverage
cc <- md.pairs(wvs_data_filter)$rr / nrow(wvs_data_filter)
cc
range(cc)
eps <- 0.8
all(cc > eps)
pat <- cc <= eps
apply(pat, 1, function(x) names(x)[x])
cc[lower.tri(cc, diag = TRUE)]
# Univariate outliers using the boxplot method
boxplot.stats(wvs_data_filter$private_state_ownership)
x <- wvs_data_filter$private_state_ownership
# Define a function to implement the boxplot method:
bpOutliers <- function(x) {
iFen <- boxplot.stats(x, coef = 1.5)$stats[c(1, 28)]
oFen <- boxplot.stats(x, coef = 3.0)$stats[c(1, 28)]
list(possible = which(x < iFen[1] | x > iFen[2]),
probable = which(x < oFen[1] | x > oFen[2])
)
}
rm(list = c("x"))
lapply(wvs_data_filter[ , -c(1, 11)], FUN = bpOutliers)
# Some EDA for plotting the outliers
hist(wvs_data_filter$education_inequality)
hist(wvs_data_filter$equal_rights)
hist(wvs_data_filter$social_class)
# Using Winsorization to treat the Univariate outliers
# For education inequality (3 is for the 1st quantile value)
summary(wvs_data_filter$education_inequality)
lower_threshold1 <- round(3.0 - IQR(wvs_data_filter$education_inequality, na.rm = TRUE) * 1.5)
lower_threshold1
wvs_data_filter$education_inequality <- replace(wvs_data_filter$education_inequality, wvs_data_filter$education_inequality < 2, lower_threshold1)
hist(wvs_data_filter$education_inequality)
# For equal rights (8 is for the 1st quantile value)
summary(wvs_data_filter$equal_rights)
lower_threshold2 <- round(8 - IQR(wvs_data_filter$equal_rights, na.rm = TRUE) * 1.5)
lower_threshold2
wvs_data_filter$equal_rights <- replace(wvs_data_filter$equal_rights, wvs_data_filter$equal_rights < 5, lower_threshold2)
hist(wvs_data_filter$equal_rights)
# For equal rights (3 is for the 1st quantile value)
summary(wvs_data_filter$social_class)
lower_threshold3 <- round(3.0 - IQR(wvs_data_filter$social_class, na.rm = TRUE) * 1.5)
lower_threshold3
wvs_data_filter$social_class <- replace(wvs_data_filter$social_class, wvs_data_filter$social_class < 2, lower_threshold3)
hist(wvs_data_filter$social_class)
predM <- quickpred(wvs_data_filter, mincor = 0.2, include = "Sex")
miceOut1 <- mice(wvs_data_filter, m = 10, maxit = 5, predictorMatrix = predM, seed = 221291)
MIlist <- complete(miceOut1, "all")
MIlist
plot(miceOut1)
# Multivariate outliers using the Mahalanodibis distance method
# MCDestimation
data  <- MIlist$`1`[ , -c(1, 11)]
prob  <- 0.99
ratio <- 0.75
mcdMahalanobis <- function(data, prob, ratio = 0.75, seed = NULL) {
if(!is.null(seed)) set.seed(seed)
stats <- cov.mcd(data, quantile.used = floor(ratio * nrow(data)))
md <- mahalanobis(x = data, center = stats$center, cov = stats$cov)
crit <- qchisq(prob, df = ncol(data))
which(md > crit)
}
rm(list = c("data", "prob", "ratio"))
# Count of which observations are outliers in more than 50% of the cases
m_out_list <- unlist(m_out)
outlier.freq <- as.data.frame(table(m_out_list))
m_out_list <- filter(outlier.freq, Freq >= 5)
m_out_list <- as.numeric(as.vector(m_out_list$m_out_list))
miceOut1_updated <- miceOut1$data[-c(m_out_list), ]
# Creating new MI list to remove the multivariate outliers
miceOut2 <- mice(miceOut1_updated, m = 10, maxit = 5, predictorMatrix = predM, seed = 221291)
MIlist_updated <- complete(miceOut2, "all")
MIlist_updated
MIlist_updated <- complete(miceOut2, "all")
MIlist_updated
## Individual simple linear regression to find significant predictors.
fitsReg1 <- lm.mids(view_on_competition ~ business_inequality, data = miceOut2)
fitsReg2 <- lm.mids(view_on_competition ~ equal_rights, data = miceOut2)
fitsReg3 <- lm.mids(view_on_competition ~ income_equality, data = miceOut2)
fitsReg4 <- lm.mids(view_on_competition ~ availableJob_inequality, data = miceOut2)
fitsReg5 <- lm.mids(view_on_competition ~ Whouse_fulfillment, data = miceOut2)
fitsReg6 <- lm.mids(view_on_competition ~ Whouse_fulfillment + equal_rights, data = miceOut2)
fitsReg7 <- lm.mids(view_on_competition ~ Whouse_fulfillment + availableJob_inequality + equal_rights, data = miceOut2)
fitsReg8 <- lm.mids(view_on_competition ~ Whouse_fulfillment + availableJob_inequality + equal_rights + business_inequality, data = miceOut2)
# Pool an arbitrary list of fitted models:
poolFit1 <- pool(fitsReg1)
poolFit2 <- pool(fitsReg2)
poolFit3 <- pool(fitsReg3)
poolFit4 <- pool(fitsReg4)
poolFit5 <- pool(fitsReg5)
poolFit6 <- pool(fitsReg6)
poolFit7 <- pool(fitsReg7)
poolFit8 <- pool(fitsReg8)
# Summarize pooled results:
summary(poolFit1)
summary(poolFit2)
summary(poolFit3)
summary(poolFit4)
summary(poolFit5)
summary(poolFit6)
summary(poolFit7)
summary(poolFit8)
# Cleanup to start
rm(list = ls(all = TRUE))
# Cleanup to start
rm(list = ls(all = TRUE))
setwd("~/TILBURG UNIVERSITY/M_DATA_SCIENCE_AND_SOCIETY/Stats and Methodology/Project/group36/code")
# Load packages needed for data cleaning:
library(mice) # For missing data descriptives & MI
library(MASS) # For robust stats
library(naniar) # For NA values
library(dplyr) # For filtering the dataset
library(mitools) # For MI
library(MLmetrics) # We'll need this for MSEs
## Source the "studentFunctions.R" script to get the cv.lm function:
source("studentFunctions.R")
## Source the "miPredictionRoutines.R" script to get MI-based prediction stuff:
source("miPredictionRoutines.R")
set.seed(221291) # Set the random number seed
# Define the data directory:
dataDir <- "../data/"
## Load the data file ##
wvs_data <- readRDS(paste0(dataDir, "wvs_data.rds"))
## Load the data file ##
wvs_data <- readRDS(paste0(dataDir, "wvs_data.rds"))
# Get the variables that are relevant for our analysis
wvs_data_filter <- wvs_data %>% select(V2, V8, V45, V47:V48, V52, V53:V54, V96,
V139, V240, V242,
V71, V81, V97, V99, V101,
V181:V182, V229, V237:V239,
V23, V57:V58, V191, V59)
# Changing names of the variables so they are more informative (Gender Politics)
wvs_data_filter <- wvs_data_filter %>% rename(country_code = V2, availableJob_inequality = V45, Wwage_inequality = V47, Wjob_independence = V48,
education_inequality = V52, business_inequality = V53, Whouse_fulfillment = V54,
equal_rights = V139, Sex = V240, Age = V242)
# Changing names of the variables so they are more informative (Economic Beliefs)
wvs_data_filter <- wvs_data_filter %>% rename(work_importance = V8, importance_wealth = V71, economy_environment = V81, income_equality = V96,
private_state_ownership = V97, view_on_competition = V99, wealth_accumulation = V101,
job_security = V181, employment_status = V229, family_saving = V237,
social_class = V238, scale_income = V239)
negative_values <- c(-1:-5)
wvs_data_filter <- replace_with_na_all(wvs_data_filter, ~.x %in% negative_values)
wvs_data_filter
summary(wvs_data_filter)
# Count the missing values in each feature
cm <- colSums(is.na(wvs_data_filter))
cm
pm <- colMeans(is.na(wvs_data_filter))
pm
# Count the observed values in each feature
co <- colSums(!is.na(wvs_data_filter))
co
po <- colMeans(!is.na(wvs_data_filter))
po
# Alternative of observed values
nrow(wvs_data_filter) - cm
1 - pm
# Alternative of missing values
nrow(wvs_data_filter) - co
1 - po
# Some stats on the missing percentages
range(pm)
mean(pm)
median(pm)
# All features that miss at least 10% of their data
pm[pm > 0.1]
# Missing patterns in the data
missPat <- md.pattern(wvs_data_filter)
missPat
dev.off()
missPat[ , ncol(missPat)]
missPat[-nrow(missPat), ncol(missPat)]
as.numeric(rownames(missPat))
as.numeric(rownames(missPat))[-nrow(missPat)]
# Covariance coverage
cc <- md.pairs(wvs_data_filter)$rr / nrow(wvs_data_filter)
cc
range(cc)
eps <- 0.8
all(cc > eps)
pat <- cc <= eps
apply(pat, 1, function(x) names(x)[x])
cc[lower.tri(cc, diag = TRUE)]
# Univariate outliers using the boxplot method
boxplot.stats(wvs_data_filter$private_state_ownership)
# Univariate outliers using the boxplot method
boxplot.stats(wvs_data_filter$private_state_ownership)
x <- wvs_data_filter$private_state_ownership
# Define a function to implement the boxplot method:
bpOutliers <- function(x) {
iFen <- boxplot.stats(x, coef = 1.5)$stats[c(1, 28)]
oFen <- boxplot.stats(x, coef = 3.0)$stats[c(1, 28)]
list(possible = which(x < iFen[1] | x > iFen[2]),
probable = which(x < oFen[1] | x > oFen[2])
)
}
rm(list = c("x"))
lapply(wvs_data_filter[ , -c(1, 11)], FUN = bpOutliers)
# Some EDA for plotting the outliers
hist(wvs_data_filter$education_inequality)
hist(wvs_data_filter$equal_rights)
hist(wvs_data_filter$social_class)
# Using Winsorization to treat the Univariate outliers
# For education inequality (3 is for the 1st quantile value)
summary(wvs_data_filter$education_inequality)
lower_threshold1 <- round(3.0 - IQR(wvs_data_filter$education_inequality, na.rm = TRUE) * 1.5)
lower_threshold1
wvs_data_filter$education_inequality <- replace(wvs_data_filter$education_inequality, wvs_data_filter$education_inequality < 2, lower_threshold1)
hist(wvs_data_filter$education_inequality)
# For equal rights (8 is for the 1st quantile value)
summary(wvs_data_filter$equal_rights)
lower_threshold2 <- round(8 - IQR(wvs_data_filter$equal_rights, na.rm = TRUE) * 1.5)
lower_threshold2
wvs_data_filter$equal_rights <- replace(wvs_data_filter$equal_rights, wvs_data_filter$equal_rights < 5, lower_threshold2)
hist(wvs_data_filter$equal_rights)
# For equal rights (3 is for the 1st quantile value)
summary(wvs_data_filter$social_class)
lower_threshold3 <- round(3.0 - IQR(wvs_data_filter$social_class, na.rm = TRUE) * 1.5)
lower_threshold3
wvs_data_filter$social_class <- replace(wvs_data_filter$social_class, wvs_data_filter$social_class < 2, lower_threshold3)
hist(wvs_data_filter$social_class)
predM <- quickpred(wvs_data_filter, mincor = 0.2, include = "Sex")
predM <- quickpred(wvs_data_filter, mincor = 0.2, include = "Sex")
miceOut1 <- mice(wvs_data_filter, m = 10, maxit = 5, predictorMatrix = predM, seed = 221291)
MIlist <- complete(miceOut1, "all")
MIlist
plot(miceOut1)
dev.off()
# Multivariate outliers using the Mahalanodibis distance method
# MCDestimation
data  <- MIlist$`1`[ , -c(1, 11)]
prob  <- 0.99
ratio <- 0.75
mcdMahalanobis <- function(data, prob, ratio = 0.75, seed = NULL) {
if(!is.null(seed)) set.seed(seed)
stats <- cov.mcd(data, quantile.used = floor(ratio * nrow(data)))
md <- mahalanobis(x = data, center = stats$center, cov = stats$cov)
crit <- qchisq(prob, df = ncol(data))
which(md > crit)
}
rm(list = c("data", "prob", "ratio"))
m_out <- lapply(MIlist,
function(x) mcdMahalanobis(prob = 0.99, seed = 221291, data = x))
# Count of which observations are outliers in more than 50% of the cases
m_out_list <- unlist(m_out)
m_out <- lapply(MIlist,
function(x) mcdMahalanobis(prob = 0.99, seed = 221291, data = x))
